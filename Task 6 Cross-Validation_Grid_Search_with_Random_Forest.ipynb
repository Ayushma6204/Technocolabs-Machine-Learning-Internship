{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the following two cells before you begin.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the following 3 cells to create a list of features, create a train/test split, and instantiate a random forest classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMIT_BAL',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_1',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6',\n",
       " 'default payment next month']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_response = df.columns.tolist()\n",
    "items_to_remove = ['ID', 'SEX', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "                   'EDUCATION_CAT', 'graduate school', 'high school', 'none',\n",
    "                   'others', 'university']\n",
    "features_response = [item for item in features_response if item not in items_to_remove]\n",
    "features_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features_response[:-1]].values,\n",
    "    df['default payment next month'].values,\n",
    "    test_size=0.2, random_state=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=10, criterion='gini', max_depth=3,\n",
    "    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None,\n",
    "    random_state=4, verbose=0, warm_start=False, class_weight=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary representing the grid for the `max_depth` and `n_estimators` hyperparameters that will be searched. Include depths of 3, 6, 9, and 12, and 10, 50, 100, and 200 trees.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':[3,9,12,10,50,100,200],'n_estimators':[10,50,100,200]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________\n",
    "**Instantiate a `GridSearchCV` object using the same options that we have previously in this course, but with the dictionary of hyperparameters created above. Set `verbose=2` to see the output for each fit performed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "cv = GridSearchCV(rf, param_grid=params,scoring='roc_auc',\n",
    "                  n_jobs=-1, iid=False, refit=True, cv=4, verbose=2, error_score=np.nan, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____________________________________________________\n",
    "**Fit the `GridSearchCV` object on the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 28 candidates, totalling 112 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=3,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False, random_state=4,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 9, 12, 10, 50, 100, 200],\n",
       "                         'n_estimators': [10, 50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________\n",
    "**Put the results of the grid search in a pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.363634</td>\n",
       "      <td>0.081077</td>\n",
       "      <td>0.034240</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 10}</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.766194</td>\n",
       "      <td>0.759475</td>\n",
       "      <td>0.743870</td>\n",
       "      <td>0.760662</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>18</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.763199</td>\n",
       "      <td>0.770383</td>\n",
       "      <td>0.768790</td>\n",
       "      <td>0.765756</td>\n",
       "      <td>3.975080e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.265345</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>0.068728</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 50}</td>\n",
       "      <td>0.776417</td>\n",
       "      <td>0.774413</td>\n",
       "      <td>0.758292</td>\n",
       "      <td>0.748397</td>\n",
       "      <td>0.764380</td>\n",
       "      <td>0.011598</td>\n",
       "      <td>13</td>\n",
       "      <td>0.769038</td>\n",
       "      <td>0.767107</td>\n",
       "      <td>0.774445</td>\n",
       "      <td>0.776093</td>\n",
       "      <td>0.771671</td>\n",
       "      <td>3.708698e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.490455</td>\n",
       "      <td>0.072374</td>\n",
       "      <td>0.098219</td>\n",
       "      <td>0.027617</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.775328</td>\n",
       "      <td>0.775094</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>0.749097</td>\n",
       "      <td>0.764449</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>12</td>\n",
       "      <td>0.768155</td>\n",
       "      <td>0.768331</td>\n",
       "      <td>0.773938</td>\n",
       "      <td>0.775587</td>\n",
       "      <td>0.771503</td>\n",
       "      <td>3.312129e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.617527</td>\n",
       "      <td>0.096493</td>\n",
       "      <td>0.176693</td>\n",
       "      <td>0.018345</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 200}</td>\n",
       "      <td>0.775546</td>\n",
       "      <td>0.773983</td>\n",
       "      <td>0.758675</td>\n",
       "      <td>0.750389</td>\n",
       "      <td>0.764648</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>11</td>\n",
       "      <td>0.768853</td>\n",
       "      <td>0.768023</td>\n",
       "      <td>0.773623</td>\n",
       "      <td>0.776227</td>\n",
       "      <td>0.771681</td>\n",
       "      <td>3.384419e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.578065</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>0.026492</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 10}</td>\n",
       "      <td>0.780155</td>\n",
       "      <td>0.770939</td>\n",
       "      <td>0.763128</td>\n",
       "      <td>0.751761</td>\n",
       "      <td>0.766496</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>10</td>\n",
       "      <td>0.841328</td>\n",
       "      <td>0.846406</td>\n",
       "      <td>0.856082</td>\n",
       "      <td>0.848704</td>\n",
       "      <td>0.848130</td>\n",
       "      <td>5.310606e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.667898</td>\n",
       "      <td>0.044843</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 50}</td>\n",
       "      <td>0.789091</td>\n",
       "      <td>0.784664</td>\n",
       "      <td>0.769314</td>\n",
       "      <td>0.763039</td>\n",
       "      <td>0.776527</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>6</td>\n",
       "      <td>0.858836</td>\n",
       "      <td>0.866019</td>\n",
       "      <td>0.869223</td>\n",
       "      <td>0.867517</td>\n",
       "      <td>0.865399</td>\n",
       "      <td>3.954733e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.839136</td>\n",
       "      <td>0.051249</td>\n",
       "      <td>0.125210</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 100}</td>\n",
       "      <td>0.790593</td>\n",
       "      <td>0.786058</td>\n",
       "      <td>0.771647</td>\n",
       "      <td>0.764219</td>\n",
       "      <td>0.778129</td>\n",
       "      <td>0.010650</td>\n",
       "      <td>3</td>\n",
       "      <td>0.860308</td>\n",
       "      <td>0.868584</td>\n",
       "      <td>0.871058</td>\n",
       "      <td>0.869815</td>\n",
       "      <td>0.867441</td>\n",
       "      <td>4.210142e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10.991994</td>\n",
       "      <td>0.094830</td>\n",
       "      <td>0.279662</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 200}</td>\n",
       "      <td>0.791313</td>\n",
       "      <td>0.786984</td>\n",
       "      <td>0.774450</td>\n",
       "      <td>0.763902</td>\n",
       "      <td>0.779162</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861790</td>\n",
       "      <td>0.868840</td>\n",
       "      <td>0.871868</td>\n",
       "      <td>0.870697</td>\n",
       "      <td>0.868299</td>\n",
       "      <td>3.909631e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.776500</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.021244</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 10}</td>\n",
       "      <td>0.773111</td>\n",
       "      <td>0.762049</td>\n",
       "      <td>0.744532</td>\n",
       "      <td>0.736969</td>\n",
       "      <td>0.754165</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>25</td>\n",
       "      <td>0.915965</td>\n",
       "      <td>0.923355</td>\n",
       "      <td>0.920788</td>\n",
       "      <td>0.923045</td>\n",
       "      <td>0.920788</td>\n",
       "      <td>2.955657e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.456146</td>\n",
       "      <td>0.025638</td>\n",
       "      <td>0.087973</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 50}</td>\n",
       "      <td>0.787161</td>\n",
       "      <td>0.781517</td>\n",
       "      <td>0.764827</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.771735</td>\n",
       "      <td>0.013381</td>\n",
       "      <td>9</td>\n",
       "      <td>0.935475</td>\n",
       "      <td>0.943611</td>\n",
       "      <td>0.939708</td>\n",
       "      <td>0.941929</td>\n",
       "      <td>0.940181</td>\n",
       "      <td>3.049242e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.980271</td>\n",
       "      <td>0.043462</td>\n",
       "      <td>0.145704</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 100}</td>\n",
       "      <td>0.790205</td>\n",
       "      <td>0.782707</td>\n",
       "      <td>0.769887</td>\n",
       "      <td>0.757711</td>\n",
       "      <td>0.775128</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>7</td>\n",
       "      <td>0.936854</td>\n",
       "      <td>0.943268</td>\n",
       "      <td>0.942011</td>\n",
       "      <td>0.943462</td>\n",
       "      <td>0.941398</td>\n",
       "      <td>2.682396e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>13.893318</td>\n",
       "      <td>0.012553</td>\n",
       "      <td>0.293156</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>12</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 200}</td>\n",
       "      <td>0.790836</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.773486</td>\n",
       "      <td>0.760561</td>\n",
       "      <td>0.777054</td>\n",
       "      <td>0.011337</td>\n",
       "      <td>4</td>\n",
       "      <td>0.939174</td>\n",
       "      <td>0.943913</td>\n",
       "      <td>0.942954</td>\n",
       "      <td>0.944652</td>\n",
       "      <td>0.942673</td>\n",
       "      <td>2.107839e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.596308</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>0.018245</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 10}</td>\n",
       "      <td>0.775230</td>\n",
       "      <td>0.770802</td>\n",
       "      <td>0.755406</td>\n",
       "      <td>0.748566</td>\n",
       "      <td>0.762501</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>16</td>\n",
       "      <td>0.867015</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.878278</td>\n",
       "      <td>0.874902</td>\n",
       "      <td>0.873377</td>\n",
       "      <td>4.087560e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.119005</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.072477</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.787979</td>\n",
       "      <td>0.783216</td>\n",
       "      <td>0.768462</td>\n",
       "      <td>0.758843</td>\n",
       "      <td>0.774625</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>8</td>\n",
       "      <td>0.885376</td>\n",
       "      <td>0.892638</td>\n",
       "      <td>0.893564</td>\n",
       "      <td>0.892396</td>\n",
       "      <td>0.890994</td>\n",
       "      <td>3.272572e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.100554</td>\n",
       "      <td>0.054925</td>\n",
       "      <td>0.137706</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.790293</td>\n",
       "      <td>0.783782</td>\n",
       "      <td>0.771032</td>\n",
       "      <td>0.761268</td>\n",
       "      <td>0.776593</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>5</td>\n",
       "      <td>0.887206</td>\n",
       "      <td>0.893968</td>\n",
       "      <td>0.894637</td>\n",
       "      <td>0.895843</td>\n",
       "      <td>0.892914</td>\n",
       "      <td>3.362840e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>12.142876</td>\n",
       "      <td>0.028578</td>\n",
       "      <td>0.303654</td>\n",
       "      <td>0.029582</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.791789</td>\n",
       "      <td>0.785538</td>\n",
       "      <td>0.773063</td>\n",
       "      <td>0.763083</td>\n",
       "      <td>0.778368</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888551</td>\n",
       "      <td>0.894384</td>\n",
       "      <td>0.896272</td>\n",
       "      <td>0.897042</td>\n",
       "      <td>0.894062</td>\n",
       "      <td>3.325666e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.927202</td>\n",
       "      <td>0.026838</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 10}</td>\n",
       "      <td>0.731355</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.726835</td>\n",
       "      <td>0.708834</td>\n",
       "      <td>0.722626</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>26</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.999095</td>\n",
       "      <td>0.999104</td>\n",
       "      <td>0.998971</td>\n",
       "      <td>0.999093</td>\n",
       "      <td>8.189610e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.523305</td>\n",
       "      <td>0.060850</td>\n",
       "      <td>0.103968</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 50}</td>\n",
       "      <td>0.765106</td>\n",
       "      <td>0.763870</td>\n",
       "      <td>0.757509</td>\n",
       "      <td>0.733796</td>\n",
       "      <td>0.755070</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>22</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>7.468546e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>9.641673</td>\n",
       "      <td>0.092408</td>\n",
       "      <td>0.227178</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 100}</td>\n",
       "      <td>0.769947</td>\n",
       "      <td>0.766190</td>\n",
       "      <td>0.761632</td>\n",
       "      <td>0.739861</td>\n",
       "      <td>0.759407</td>\n",
       "      <td>0.011663</td>\n",
       "      <td>21</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>2.134313e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>18.644802</td>\n",
       "      <td>0.134798</td>\n",
       "      <td>0.427114</td>\n",
       "      <td>0.029943</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 200}</td>\n",
       "      <td>0.774908</td>\n",
       "      <td>0.768800</td>\n",
       "      <td>0.762979</td>\n",
       "      <td>0.742957</td>\n",
       "      <td>0.762411</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>4.628634e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.958441</td>\n",
       "      <td>0.022812</td>\n",
       "      <td>0.028992</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'n_estimators': 10}</td>\n",
       "      <td>0.731355</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.726835</td>\n",
       "      <td>0.708834</td>\n",
       "      <td>0.722626</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>26</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.999095</td>\n",
       "      <td>0.999104</td>\n",
       "      <td>0.998971</td>\n",
       "      <td>0.999093</td>\n",
       "      <td>8.189610e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>4.586035</td>\n",
       "      <td>0.094147</td>\n",
       "      <td>0.126961</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 100, 'n_estimators': 50}</td>\n",
       "      <td>0.765106</td>\n",
       "      <td>0.763870</td>\n",
       "      <td>0.757509</td>\n",
       "      <td>0.733796</td>\n",
       "      <td>0.755070</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>22</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>7.468546e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>9.490220</td>\n",
       "      <td>0.142936</td>\n",
       "      <td>0.233426</td>\n",
       "      <td>0.024938</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'n_estimators': 100}</td>\n",
       "      <td>0.769947</td>\n",
       "      <td>0.766190</td>\n",
       "      <td>0.761829</td>\n",
       "      <td>0.739861</td>\n",
       "      <td>0.759457</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>2.133562e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>18.606312</td>\n",
       "      <td>0.173584</td>\n",
       "      <td>0.432613</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 100, 'n_estimators': 200}</td>\n",
       "      <td>0.775228</td>\n",
       "      <td>0.768800</td>\n",
       "      <td>0.763110</td>\n",
       "      <td>0.742957</td>\n",
       "      <td>0.762524</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>14</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>4.569737e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.968439</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.030240</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 200, 'n_estimators': 10}</td>\n",
       "      <td>0.731355</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.726835</td>\n",
       "      <td>0.708834</td>\n",
       "      <td>0.722626</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>26</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.999095</td>\n",
       "      <td>0.999104</td>\n",
       "      <td>0.998971</td>\n",
       "      <td>0.999093</td>\n",
       "      <td>8.189610e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.014899</td>\n",
       "      <td>0.032003</td>\n",
       "      <td>0.106717</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 200, 'n_estimators': 50}</td>\n",
       "      <td>0.765106</td>\n",
       "      <td>0.763870</td>\n",
       "      <td>0.757509</td>\n",
       "      <td>0.733796</td>\n",
       "      <td>0.755070</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>22</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>7.468546e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>9.029120</td>\n",
       "      <td>0.093642</td>\n",
       "      <td>0.202186</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 200, 'n_estimators': 100}</td>\n",
       "      <td>0.769947</td>\n",
       "      <td>0.766190</td>\n",
       "      <td>0.761829</td>\n",
       "      <td>0.739861</td>\n",
       "      <td>0.759457</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>2.133562e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>19.166385</td>\n",
       "      <td>0.170993</td>\n",
       "      <td>0.489594</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 200, 'n_estimators': 200}</td>\n",
       "      <td>0.775228</td>\n",
       "      <td>0.768800</td>\n",
       "      <td>0.763110</td>\n",
       "      <td>0.742957</td>\n",
       "      <td>0.762524</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>14</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>4.569737e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.363634      0.081077         0.034240        0.016355   \n",
       "1        1.265345      0.010032         0.068728        0.012790   \n",
       "2        2.490455      0.072374         0.098219        0.027617   \n",
       "3        4.617527      0.096493         0.176693        0.018345   \n",
       "4        0.578065      0.016763         0.026492        0.012274   \n",
       "5        2.667898      0.044843         0.066481        0.001118   \n",
       "6        5.839136      0.051249         0.125210        0.000829   \n",
       "7       10.991994      0.094830         0.279662        0.014749   \n",
       "8        0.776500      0.040004         0.021244        0.000829   \n",
       "9        3.456146      0.025638         0.087973        0.012016   \n",
       "10       6.980271      0.043462         0.145704        0.001478   \n",
       "11      13.893318      0.012553         0.293156        0.003191   \n",
       "12       0.596308      0.019455         0.018245        0.001089   \n",
       "13       3.119005      0.064559         0.072477        0.003041   \n",
       "14       6.100554      0.054925         0.137706        0.007914   \n",
       "15      12.142876      0.028578         0.303654        0.029582   \n",
       "16       0.927202      0.026838         0.024493        0.000500   \n",
       "17       4.523305      0.060850         0.103968        0.002449   \n",
       "18       9.641673      0.092408         0.227178        0.024460   \n",
       "19      18.644802      0.134798         0.427114        0.029943   \n",
       "20       0.958441      0.022812         0.028992        0.003936   \n",
       "21       4.586035      0.094147         0.126961        0.013689   \n",
       "22       9.490220      0.142936         0.233426        0.024938   \n",
       "23      18.606312      0.173584         0.432613        0.015102   \n",
       "24       0.968439      0.020637         0.030240        0.004602   \n",
       "25       5.014899      0.032003         0.106717        0.002861   \n",
       "26       9.029120      0.093642         0.202186        0.005213   \n",
       "27      19.166385      0.170993         0.489594        0.021163   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0                3                 10   \n",
       "1                3                 50   \n",
       "2                3                100   \n",
       "3                3                200   \n",
       "4                9                 10   \n",
       "5                9                 50   \n",
       "6                9                100   \n",
       "7                9                200   \n",
       "8               12                 10   \n",
       "9               12                 50   \n",
       "10              12                100   \n",
       "11              12                200   \n",
       "12              10                 10   \n",
       "13              10                 50   \n",
       "14              10                100   \n",
       "15              10                200   \n",
       "16              50                 10   \n",
       "17              50                 50   \n",
       "18              50                100   \n",
       "19              50                200   \n",
       "20             100                 10   \n",
       "21             100                 50   \n",
       "22             100                100   \n",
       "23             100                200   \n",
       "24             200                 10   \n",
       "25             200                 50   \n",
       "26             200                100   \n",
       "27             200                200   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0      {'max_depth': 3, 'n_estimators': 10}           0.773109   \n",
       "1      {'max_depth': 3, 'n_estimators': 50}           0.776417   \n",
       "2     {'max_depth': 3, 'n_estimators': 100}           0.775328   \n",
       "3     {'max_depth': 3, 'n_estimators': 200}           0.775546   \n",
       "4      {'max_depth': 9, 'n_estimators': 10}           0.780155   \n",
       "5      {'max_depth': 9, 'n_estimators': 50}           0.789091   \n",
       "6     {'max_depth': 9, 'n_estimators': 100}           0.790593   \n",
       "7     {'max_depth': 9, 'n_estimators': 200}           0.791313   \n",
       "8     {'max_depth': 12, 'n_estimators': 10}           0.773111   \n",
       "9     {'max_depth': 12, 'n_estimators': 50}           0.787161   \n",
       "10   {'max_depth': 12, 'n_estimators': 100}           0.790205   \n",
       "11   {'max_depth': 12, 'n_estimators': 200}           0.790836   \n",
       "12    {'max_depth': 10, 'n_estimators': 10}           0.775230   \n",
       "13    {'max_depth': 10, 'n_estimators': 50}           0.787979   \n",
       "14   {'max_depth': 10, 'n_estimators': 100}           0.790293   \n",
       "15   {'max_depth': 10, 'n_estimators': 200}           0.791789   \n",
       "16    {'max_depth': 50, 'n_estimators': 10}           0.731355   \n",
       "17    {'max_depth': 50, 'n_estimators': 50}           0.765106   \n",
       "18   {'max_depth': 50, 'n_estimators': 100}           0.769947   \n",
       "19   {'max_depth': 50, 'n_estimators': 200}           0.774908   \n",
       "20   {'max_depth': 100, 'n_estimators': 10}           0.731355   \n",
       "21   {'max_depth': 100, 'n_estimators': 50}           0.765106   \n",
       "22  {'max_depth': 100, 'n_estimators': 100}           0.769947   \n",
       "23  {'max_depth': 100, 'n_estimators': 200}           0.775228   \n",
       "24   {'max_depth': 200, 'n_estimators': 10}           0.731355   \n",
       "25   {'max_depth': 200, 'n_estimators': 50}           0.765106   \n",
       "26  {'max_depth': 200, 'n_estimators': 100}           0.769947   \n",
       "27  {'max_depth': 200, 'n_estimators': 200}           0.775228   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0            0.766194           0.759475           0.743870         0.760662   \n",
       "1            0.774413           0.758292           0.748397         0.764380   \n",
       "2            0.775094           0.758278           0.749097         0.764449   \n",
       "3            0.773983           0.758675           0.750389         0.764648   \n",
       "4            0.770939           0.763128           0.751761         0.766496   \n",
       "5            0.784664           0.769314           0.763039         0.776527   \n",
       "6            0.786058           0.771647           0.764219         0.778129   \n",
       "7            0.786984           0.774450           0.763902         0.779162   \n",
       "8            0.762049           0.744532           0.736969         0.754165   \n",
       "9            0.781517           0.764827           0.753437         0.771735   \n",
       "10           0.782707           0.769887           0.757711         0.775128   \n",
       "11           0.783333           0.773486           0.760561         0.777054   \n",
       "12           0.770802           0.755406           0.748566         0.762501   \n",
       "13           0.783216           0.768462           0.758843         0.774625   \n",
       "14           0.783782           0.771032           0.761268         0.776593   \n",
       "15           0.785538           0.773063           0.763083         0.778368   \n",
       "16           0.723478           0.726835           0.708834         0.722626   \n",
       "17           0.763870           0.757509           0.733796         0.755070   \n",
       "18           0.766190           0.761632           0.739861         0.759407   \n",
       "19           0.768800           0.762979           0.742957         0.762411   \n",
       "20           0.723478           0.726835           0.708834         0.722626   \n",
       "21           0.763870           0.757509           0.733796         0.755070   \n",
       "22           0.766190           0.761829           0.739861         0.759457   \n",
       "23           0.768800           0.763110           0.742957         0.762524   \n",
       "24           0.723478           0.726835           0.708834         0.722626   \n",
       "25           0.763870           0.757509           0.733796         0.755070   \n",
       "26           0.766190           0.761829           0.739861         0.759457   \n",
       "27           0.768800           0.763110           0.742957         0.762524   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.010827               18            0.760652            0.763199   \n",
       "1         0.011598               13            0.769038            0.767107   \n",
       "2         0.011241               12            0.768155            0.768331   \n",
       "3         0.010547               11            0.768853            0.768023   \n",
       "4         0.010426               10            0.841328            0.846406   \n",
       "5         0.010701                6            0.858836            0.866019   \n",
       "6         0.010650                3            0.860308            0.868584   \n",
       "7         0.010769                1            0.861790            0.868840   \n",
       "8         0.014227               25            0.915965            0.923355   \n",
       "9         0.013381                9            0.935475            0.943611   \n",
       "10        0.012405                7            0.936854            0.943268   \n",
       "11        0.011337                4            0.939174            0.943913   \n",
       "12        0.010902               16            0.867015            0.873315   \n",
       "13        0.011610                8            0.885376            0.892638   \n",
       "14        0.011238                5            0.887206            0.893968   \n",
       "15        0.011105                2            0.888551            0.894384   \n",
       "16        0.008439               26            0.999202            0.999095   \n",
       "17        0.012617               22            0.999993            0.999986   \n",
       "18        0.011663               21            0.999998            0.999995   \n",
       "19        0.011998               17            0.999998            0.999997   \n",
       "20        0.008439               26            0.999202            0.999095   \n",
       "21        0.012617               22            0.999993            0.999986   \n",
       "22        0.011673               19            0.999998            0.999995   \n",
       "23        0.012083               14            0.999998            0.999997   \n",
       "24        0.008439               26            0.999202            0.999095   \n",
       "25        0.012617               22            0.999993            0.999986   \n",
       "26        0.011673               19            0.999998            0.999995   \n",
       "27        0.012083               14            0.999998            0.999997   \n",
       "\n",
       "    split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0             0.770383            0.768790          0.765756     3.975080e-03  \n",
       "1             0.774445            0.776093          0.771671     3.708698e-03  \n",
       "2             0.773938            0.775587          0.771503     3.312129e-03  \n",
       "3             0.773623            0.776227          0.771681     3.384419e-03  \n",
       "4             0.856082            0.848704          0.848130     5.310606e-03  \n",
       "5             0.869223            0.867517          0.865399     3.954733e-03  \n",
       "6             0.871058            0.869815          0.867441     4.210142e-03  \n",
       "7             0.871868            0.870697          0.868299     3.909631e-03  \n",
       "8             0.920788            0.923045          0.920788     2.955657e-03  \n",
       "9             0.939708            0.941929          0.940181     3.049242e-03  \n",
       "10            0.942011            0.943462          0.941398     2.682396e-03  \n",
       "11            0.942954            0.944652          0.942673     2.107839e-03  \n",
       "12            0.878278            0.874902          0.873377     4.087560e-03  \n",
       "13            0.893564            0.892396          0.890994     3.272572e-03  \n",
       "14            0.894637            0.895843          0.892914     3.362840e-03  \n",
       "15            0.896272            0.897042          0.894062     3.325666e-03  \n",
       "16            0.999104            0.998971          0.999093     8.189610e-05  \n",
       "17            0.999986            0.999972          0.999984     7.468546e-06  \n",
       "18            0.999995            0.999992          0.999995     2.134313e-06  \n",
       "19            0.999998            0.999998          0.999998     4.628634e-07  \n",
       "20            0.999104            0.998971          0.999093     8.189610e-05  \n",
       "21            0.999986            0.999972          0.999984     7.468546e-06  \n",
       "22            0.999995            0.999992          0.999995     2.133562e-06  \n",
       "23            0.999998            0.999998          0.999998     4.569737e-07  \n",
       "24            0.999104            0.998971          0.999093     8.189610e-05  \n",
       "25            0.999986            0.999972          0.999984     7.468546e-06  \n",
       "26            0.999995            0.999992          0.999995     2.133562e-06  \n",
       "27            0.999998            0.999998          0.999998     4.569737e-07  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df = pd.DataFrame(cv.cv_results_)\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the best hyperparameters from the cross-validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 200}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "**Create a `pcolormesh` visualization of the mean testing score for each combination of hyperparameters.**\n",
    "\n",
    "<details>\n",
    "    <summary>Hint:</summary>\n",
    "    Remember to reshape the values of the mean testing scores to be a two-dimensional 4x4 grid.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10],\n",
       "       [11, 12, 13, 14, 15],\n",
       "       [16, 17, 18, 19, 20],\n",
       "       [21, 22, 23, 24, 25]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 5x5 grid\n",
    "xx_example, yy_example = np.meshgrid(range(5), range(5))\n",
    "z_example = np.arange(1,26).reshape(5,5)\n",
    "z_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Y coordinate')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set color map to `plt.cm.jet`\n",
    "ax = plt.axes()\n",
    "pcolor_ex = ax.pcolormesh(xx_example, yy_example, z_example, cmap=plt.cm.jet)\n",
    "plt.colorbar(pcolor_ex, label='Color scale')\n",
    "ax.set_xlabel('X coordinate')\n",
    "ax.set_ylabel('Y coordinate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "f0c62"
   },
   "outputs": [],
   "source": [
    "# Visualize pcolormesh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________\n",
    "**Conclude which set of hyperparameters to use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the feature names and importance\n",
    "data_act=pd.DataFrame({'Feature name':features_response[:-1],'Importance':cv.best_estimator_.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PAY_1</td>\n",
       "      <td>0.447904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LIMIT_BAL</td>\n",
       "      <td>0.056136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PAY_AMT1</td>\n",
       "      <td>0.055068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PAY_AMT2</td>\n",
       "      <td>0.048117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>BILL_AMT1</td>\n",
       "      <td>0.041400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PAY_AMT3</td>\n",
       "      <td>0.040539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>BILL_AMT2</td>\n",
       "      <td>0.038919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>BILL_AMT3</td>\n",
       "      <td>0.036369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PAY_AMT4</td>\n",
       "      <td>0.032750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>BILL_AMT4</td>\n",
       "      <td>0.032443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>BILL_AMT6</td>\n",
       "      <td>0.032279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>BILL_AMT5</td>\n",
       "      <td>0.030418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AGE</td>\n",
       "      <td>0.030072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>PAY_AMT5</td>\n",
       "      <td>0.028767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>PAY_AMT6</td>\n",
       "      <td>0.028604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MARRIAGE</td>\n",
       "      <td>0.005315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature name  Importance\n",
       "4         PAY_1    0.447904\n",
       "0     LIMIT_BAL    0.056136\n",
       "11     PAY_AMT1    0.055068\n",
       "12     PAY_AMT2    0.048117\n",
       "5     BILL_AMT1    0.041400\n",
       "13     PAY_AMT3    0.040539\n",
       "6     BILL_AMT2    0.038919\n",
       "7     BILL_AMT3    0.036369\n",
       "14     PAY_AMT4    0.032750\n",
       "8     BILL_AMT4    0.032443\n",
       "10    BILL_AMT6    0.032279\n",
       "9     BILL_AMT5    0.030418\n",
       "3           AGE    0.030072\n",
       "15     PAY_AMT5    0.028767\n",
       "16     PAY_AMT6    0.028604\n",
       "1     EDUCATION    0.014900\n",
       "2      MARRIAGE    0.005315"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort values by importance\n",
    "data_act.sort_values('Importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
